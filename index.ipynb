{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Bias-Variance Tradeoff\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Agenda\n", "\n", "1. Explain what bias, variance, and error are in the context of statistical modeling\n", "2. Explain how bias, variance and error are related via the bias-variance tradeoff\n", "3. Explain how a holdout set can be used to evaluate a model\n", "4. Use a test set to estimate model bias, variance and error\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 1. Explain what bias, variance, and error are in the context of statistical modeling"]}, {"cell_type": "markdown", "metadata": {}, "source": ["![which model is better](img/which_model_is_better.png)\n", "\n", "https://towardsdatascience.com/cultural-overfitting-and-underfitting-or-why-the-netflix-culture-wont-work-in-your-company-af2a62e41288\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# What makes a model good?\n", "\n", "- We don\u2019t ultimately care about how well your model fits your data.\n", "\n", "- What we really care about is how well your model describes the process that generated your data.\n", "\n", "- Why? Because the data set you have is but one sample from a universe of possible data sets, and you want a model that would work for any data set from that universe"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# What is a \u201cModel\u201d?\n", "\n", " - A \u201cmodel\u201d is a general specification of relationships among variables and parameters.\n", "E.G. Linear regression, or \n", "\n", "$$\\Large Price = \\beta_1 X_1 + \\beta_0 + \\epsilon$$\n", "\n", " - A \u201ctrained model\u201d is a particular model with parameters estimated using some training data.\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Remember Expected Value?\n", "\n", "- The expected value of a quantity is the weighted average of that quantity across all possible samples\n", "\n", "![6 sided die](https://media.giphy.com/media/sRJdpUSr7W0AiQ3RcM/giphy.gif)\n", "- The expected value of a 6-sided die is:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Suppose we created a model which always predicted that the die roll would be 3.\n", "\n", "The **bias** of our model would be the difference between the our expected prediction (3) and the expected value (3.5).\n", "\n", "What would the **variance** of our model be?\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Defining Error\n", "\n", "There are 3 types of prediction error: bias, variance, and irreducible error.\n", "\n", "$Total Error = Prediction\\ Error+ Irreducible\\ Error$\n", "\n", "![defining error](img/defining_error.png)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["$Total Error = Residual = Prediction\\ Error+ Irreducible\\ Error$\n", "> For regression, \u201cerror\u201d usually refers to prediction error or to residuals <br>Prediction errors are approximated by residuals\n", "\n", "### Regression fit statistics are often called \u201cerror\u201d\n", " - Sum of Squared Errors (SSE)\n", " - Mean Squared Error (MSE) \n", "     - Calculated using residuals\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["![residuals](img/residuals.png)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 2. Explain how bias, variance and error are related via the bias-variance tradeoff\n", "\n", "\n", "**Let's do a thought experiment:**\n", "\n", "1. Imagine you've collected 5 different training sets for the same problem.\n", "2. Now imagine using one algorithm to train 5 models, one for each of your training sets.\n", "3. Bias vs. variance refers to the accuracy vs. consistency of the models trained by your algorithm.\n", "\n", "![target_bias_variance](img/target.png)\n", "\n", "http://scott.fortmann-roe.com/docs/BiasVariance.html"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Defining Model Bias and Variance\n", "\n", "**Model Bias** is the expected prediction error from your expected trained model\n", "\n", "**Model Variance** is the expected variation in predictions, relative to your expected trained model\n", "\n", "**High bias** algorithms tend to be less complex, with simple or rigid underlying structure.\n", "\n", "+ They train models that are consistent, but inaccurate on average.\n", "+ These include linear or parametric algorithms such as regression and naive Bayes.\n", "\n", "On the other hand, **high variance** algorithms tend to be more complex, with flexible underlying structure.\n", "\n", "+ They train models that are accurate on average, but inconsistent.\n", "+ These include non-linear or non-parametric algorithms such as decision trees and nearest neighbors."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Let's take a look at our familiar King County housing data. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\Large Total Error = Model\\ Bias^2 + Model\\ Variance + Irreducible\\ Error$\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["![optimal](img/optimal_bias_variance.png)\n", "http://scott.fortmann-roe.com/docs/BiasVariance.html"]}, {"cell_type": "markdown", "metadata": {}, "source": ["![which_model](img/which_model_is_better_2.png)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Train Test Split"]}, {"cell_type": "markdown", "metadata": {}, "source": ["It is hard to know if your model is too simple or complex by just using it on training data.\n", "\n", "We can hold out part of our training sample, and use it as a test sample and use it to monitor our prediction error.\n", "\n", "This allows us to evaluate whether our model has the right balance of bias/variance. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["<img src='img/testtrainsplit.png' width =550 />"]}, {"cell_type": "markdown", "metadata": {}, "source": ["* **training set** \u2014a subset to train a model.\n", "* **test set**\u2014a subset to test the trained model.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Should you ever train on your test set?  \n", "\n", "\n", "![no](https://media.giphy.com/media/d10dMmzqCYqQ0/giphy.gif)\n", "\n", "\n", "**Never train on test data.** If you are seeing surprisingly good results on your evaluation metrics, it might be a sign that you are accidentally training on the test set. \n", "\n", "##### [Link](https://datascience.stackexchange.com/questions/38395/standardscaler-before-and-after-splitting-data) about data leakage and scalars"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**How do we know if our model is overfitting or underfitting?**\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["If our model is not performing well on the training  data, we are probably underfitting it.  \n", "\n", "\n", "To know if our  model is overfitting the data, we need  to test our model on unseen data. \n", "We then measure our performance on the unseen data. \n", "\n", "If the model performs way worse on the  unseen data, it is probably  overfitting the data."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<img src='https://developers.google.com/machine-learning/crash-course/images/WorkflowWithTestSet.svg' width=500/>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's go back to our KC housing data without the polynomial transformation."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now, we create a train-test split via the sklearn model selection package."]}, {"cell_type": "markdown", "metadata": {}, "source": ["A .65 R-squared reflects a model that explains a fairly high amount of the total variance in the data. \n", "\n", "### Knowledge check\n", "How would you describe the bias of the model based on the above training R^2?"]}, {"cell_type": "code", "execution_count": 426, "metadata": {}, "outputs": [{"data": {"text/plain": ["'A model with a .65 R^2 is approaching a low bias model.'"]}, "execution_count": 426, "metadata": {}, "output_type": "execute_result"}], "source": ["\"A model with a .65 R^2 is approaching a low bias model.\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Next, we test how well the model performs on the unseen test data. Remember, we do not fit the model again. The model has calculated the optimal parameters learning from the training set.  \n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The difference between the train and test scores are low.\n", "\n", "What does that indicate about variance?"]}, {"cell_type": "code", "execution_count": 428, "metadata": {}, "outputs": [{"data": {"text/plain": ["'The model has low variance'"]}, "execution_count": 428, "metadata": {}, "output_type": "execute_result"}], "source": ["'The model has low variance'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Now, let's try the same thing with our complex, polynomial model."]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Kfolds "]}, {"cell_type": "markdown", "metadata": {}, "source": ["![kfolds](img/k_folds.png)\n", "\n", "[image via sklearn](https://scikit-learn.org/stable/modules/cross_validation.html)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In this process, we split the dataset into train and test as usual, then we perform a shuffling train test split on the train set.  \n", "\n", "KFolds holds out one fraction of the dataset, trains on the larger fraction, then calculates a test score on the held out set.  It repeats this process until each group has served as the test set.\n", "\n", "We tune our parameters on the training set using kfolds, then validate on the test data.  This allows us to build our model and check to see if it is overfit without touching the test data set.  This protects our model from bias."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Once we have an acceptable model, we train our model on the entire training set, and score on the test to validate.\n", "\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.3"}}, "nbformat": 4, "nbformat_minor": 4}